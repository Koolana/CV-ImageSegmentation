# CV-ImageSegmentation
# Классификация цветных изображений 20 домов, фотографии которых сделаны на высоте от 5 до 30 м над землей

## Начало работы

### Зависимости
Данный проект написан с помощью **Python 3** и был протестирован на совместимость со следующими библиотеками:

```
numpy==1.21.2
torch==1.10.0
torchvision==0.11.2
torchsummary==1.5.1
opencv-contrib-python==4.5.3.56
tqdm==4.62.3
scikit-learn==0.24.2
matplotlib==3.4.2
```

- __glob__: позволяет нам легко находить пути к данным внутри вложенных папок;

- __cv2__: используется в качестве библиотеки обработки изображений для чтения и предварительной обработки изображений;

- __numpy__: используется для матричных операций;

- __torch__: используется для создания классов Dataset и Dataloader, а также для преобразования данных в тензоры.

### Установка

```
git clone https://github.com/Koolana/CV-ImageSegmentation.git
```

## Запуск

Для запуска обучения и проверки модели на датасете необходимо сначала скопировать датасет в папку **datasets**, а далее взаимодействовать через блокнот Jupyter.

Подробное описание работы с примерами представлено в [блокноте Jupyter](FPN-Segmentation.ipynb)

## Датасет

Для проверки работоспособности модели и оценки точности был использован [датасет изображений с дрона](https://www.kaggle.com/datasets/bulentsiyah/semantic-drone-dataset) Aerial Semantic Segmentation Drone Dataset. Датасет содержит снимки более 20 домов, фотографии сделвны на высоте от 5 до 30 метров над землей. Камера высокого разрешения использовалась для получения изображений размером 6000 на 4000 пикселей, что соответствует 24 мегапикселем. Тренировочный набор имеет 400 общедоступных изображений, а тестовый набор состоит из 200 изображений. Фотографии хранятся в формате .jpg, а метки имеют формат .png и представляют собой изображения со значениями пикселей от 0 до 24. 

<img width="362" alt="input_goal" src="https://user-images.githubusercontent.com/90565598/169665667-5c3c4ca1-56d9-43bd-a41b-34e6df5c0e01.png">

## Описание модели

### Метод для семантики наблюдаемой сцены

Для решения задачи определения объектов интереса нами было принято решение использовать сегментацию поступающего ряда изображений с помощью модели FPN (Feature Pyramid Network). Feature Pyramid Network состоит из трёх основных частей: восходящий путь (bottom-up pathway), нисходящий путь (top-down pathway) и боковые соединения (lateral connections).
Восходящий путь (bottom-up pathway) представляет собой некую иерархическую «пирамиду» – последовательность свёрточных слоёв с уменьшающейся размерностью, в нашем случае – backbone сеть. Верхние слои сверточной сети имеют большее семантическое значение, но меньшее разрешение, а нижние наоборот. Bottom-up pathway имеет уязвимость при извлечении признаков – потеря важной информации об объекте, например, из-за зашумления небольшого, но значимого, объекта фоном, так как к концу сети информация сильно сжата и обобщена.

<img width="329" alt="1" src="https://user-images.githubusercontent.com/90565598/169665984-6a53eb3e-ad8a-4f42-b5db-24377c058a48.png">

Нисходящий путь (top-down pathway) также представляет собой «пирамиду». Карты признаков верхнего слоя этой пирамиды имеют размер карт признаков верхнего слоя bottom-up пирамиды и увеличиваются вдвое методом ближайшего соседа по направлению вниз.

<img width="235" alt="2" src="https://user-images.githubusercontent.com/90565598/169665958-7f830947-6602-4d91-9205-08bf34ff0609.png">

Таким образом в top-down сети каждая карта признаков вышележащего слоя увеличивается до размеров карты нижележащего. Помимо этого, в FPN присутствуют боковые соединения, это означает, что карты признаков соответствующих слоёв bottom-up и top-down пирамид поэлементно складываются, причём карты из bottom-up проходят свёртку 1*1.

<img width="304" alt="3" src="https://user-images.githubusercontent.com/90565598/169665934-c2741326-7154-4a27-9a9a-a6e618d50079.png">

## Обучение модели

Данная модель была обучена на 30 эпохах с использованием функции потерь **Cross entropy** и оптимизатора **SGD**.
Но обучение может остановиться, если на протяжении трех эпох при уменьшении шага точность на валидационнной выборке не уменьшается. Если на протяжении одной эпохи не растет точность на валидационной выборке, тогда уменьшается learning_rate.

## Результаты

