# CV-ImageSegmentation
# Сегментация цветных изображений с дрона с использованием Feature Pyramid Networks (FPN)

## Начало работы

### Зависимости
Данный проект написан с помощью **Python 3** и был протестирован на совместимость со следующими библиотеками:

```
numpy==1.21.2
torch==1.10.0
torchvision==0.11.2
torchsummary==1.5.1
opencv-contrib-python==4.5.3.56
tqdm==4.62.3
scikit-learn==0.24.2
matplotlib==3.4.2
```

- __glob__: позволяет нам легко находить пути к данным внутри вложенных папок;

- __cv2__: используется в качестве библиотеки обработки изображений для чтения и предварительной обработки изображений;

- __numpy__: используется для матричных операций;

- __torch__: используется для создания классов Dataset и Dataloader, а также для преобразования данных в тензоры.

### Установка

```
git clone https://github.com/Koolana/CV-ImageSegmentation.git
```

## Запуск

Для запуска обучения и проверки модели на датасете необходимо сначала скопировать датасет в папку **datasets**, а далее взаимодействовать через блокнот Jupyter.

Подробное описание работы с примерами представлено в [блокноте Jupyter](FPN-Segmentation.ipynb)

## Датасет

Для проверки работоспособности модели и оценки точности был использован [датасет изображений с дрона](https://www.kaggle.com/datasets/bulentsiyah/semantic-drone-dataset) Aerial Semantic Segmentation Drone Dataset. Датасет содержит снимки более 20 домов, фотографии сделвны на высоте от 5 до 30 метров над землей. Камера высокого разрешения использовалась для получения изображений размером 6000 на 4000 пикселей, что соответствует 24 мегапикселем. Тренировочный набор имеет 400 общедоступных изображений, а тестовый набор состоит из 200 изображений. Фотографии хранятся в формате .jpg, а метки имеют формат .png и представляют собой изображения со значениями пикселей от 0 до 24. 

## Описание модели

### Метод для семантики наблюдаемой сцены

Для решения задачи определения объектов интереса нами было принято решение использовать сегментацию поступающего ряда изображений с помощью модели FPN (Feature Pyramid Network). Feature Pyramid Network состоит из трёх основных частей: восходящий путь (bottom-up pathway), нисходящий путь (top-down pathway) и боковые соединения (lateral connections).
Восходящий путь (bottom-up pathway) представляет собой некую иерархическую «пирамиду» – последовательность свёрточных слоёв с уменьшающейся размерностью, в нашем случае – backbone сеть. Верхние слои сверточной сети имеют большее семантическое значение, но меньшее разрешение, а нижние наоборот. Bottom-up pathway имеет уязвимость при извлечении признаков – потеря важной информации об объекте, например, из-за зашумления небольшого, но значимого, объекта фоном, так как к концу сети информация сильно сжата и обобщена.

<img width="329" alt="1" src="https://user-images.githubusercontent.com/90565598/169665984-6a53eb3e-ad8a-4f42-b5db-24377c058a48.png">

Нисходящий путь (top-down pathway) также представляет собой «пирамиду». Карты признаков верхнего слоя этой пирамиды имеют размер карт признаков верхнего слоя bottom-up пирамиды и увеличиваются вдвое методом ближайшего соседа по направлению вниз.

<img width="235" alt="2" src="https://user-images.githubusercontent.com/90565598/169665958-7f830947-6602-4d91-9205-08bf34ff0609.png">

Таким образом в top-down сети каждая карта признаков вышележащего слоя увеличивается до размеров карты нижележащего. Помимо этого, в FPN присутствуют боковые соединения, это означает, что карты признаков соответствующих слоёв bottom-up и top-down пирамид поэлементно складываются, причём карты из bottom-up проходят свёртку 1*1.

<img width="304" alt="3" src="https://user-images.githubusercontent.com/90565598/169665934-c2741326-7154-4a27-9a9a-a6e618d50079.png">

Боковые соединения решают проблему затухания важных сигналов в процессе прохода по слоям, совмещая семантически важную информацию, полученную к концу первой пирамиды и более детальную информацию, полученную в ней ранее.
Таким образом в результате прохода FPN модели на выходе последнего слоя top-down pathway получаем семантическую карту входного изображения. Пример входного изображени и ихображения с целевой разметкой представлен на рисунке ниже.

<img width="362" alt="input_goal" src="https://user-images.githubusercontent.com/90565598/169665667-5c3c4ca1-56d9-43bd-a41b-34e6df5c0e01.png">

Архитектура модели представлена на изображении ниже:

<img width="347" alt="4" src="https://user-images.githubusercontent.com/90565598/169666061-33599814-9b62-4a93-91cf-b90d7c5f34aa.png">

## Обучение модели

Подготовка данных для модели. Используя функцию shuffle модуля random, перемешаем элементы списков путей к изображениям и меткам, а после - разделим на тренировочную, проверочную и валидационную части обущающей выборки.

Данная модель была обучена на 30 эпохах с использованием функции потерь **CrossEntropyLoss** и оптимизатора **SGD** с моментом 0.9.
Но обучение может остановиться, если на протяжении трех эпох при уменьшении шага точность на валидационнной выборке не уменьшается. Если на протяжении одной эпохи не растет точность на валидационной выборке, тогда уменьшается learning_rate. В процессе обучения происходит сохранение наилучшей модели. Максимальное количество эпох - 30.

График функции потерь на протяжении обучения представлен на следующем рисунке.

<img width="350" alt="5" src="https://user-images.githubusercontent.com/90565598/169666126-c00329a6-22bb-45b3-834c-82f7de7af1e7.png">

## Результаты

Накладываем целевую и результирующую сегментацию на входное изображение. Здесь представлены изображени метки (слева) и полученные нами результаты (справа).

<img width="372" alt="6" src="https://user-images.githubusercontent.com/90565598/169666154-ca8a291c-c1b4-4466-8798-232c47080fd1.png">

<img width="362" alt="7" src="https://user-images.githubusercontent.com/90565598/169666194-be90d078-d7f3-4fdd-bb1a-0de06bfe6807.png">

Авторы работы: [Андрейчик Николай](https://github.com/Koolana) и [Шутова Ксения](https://github.com/Renianida).
